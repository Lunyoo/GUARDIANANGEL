// üß† SMART GPT RESPONDER - ML INTEGRADO COM PROMPT GIGANTESCO
import { OpenAI } from 'openai'
import MLIntegratedPromptEngine from './mlIntegratedPrompt'
import { universalBandits } from '../ml/universalBandits'
import { PrismaClient } from '@prisma/client'
import { getDeliveryInfo } from './deliveryZones'

const prisma = new PrismaClient()

interface ConversationContext {
  customerId: string
  conversationId: string
  messageHistory: any[]
  customerContext: any
  banditContext: any
}

interface MLDecision {
  modelUsed: 'gpt-3.5-turbo' | 'gpt-4o-mini'
  strategy: any
  confidence: number
  reasoning: string[]
}

export class SmartGptResponder {
  private openai: OpenAI
  private promptEngine: MLIntegratedPromptEngine
  
  constructor() {
    this.openai = new OpenAI({ 
      apiKey: process.env.OPENAI_API_KEY || process.env.OPENAI_KEY 
    })
    this.promptEngine = new MLIntegratedPromptEngine(universalBandits)
  }
  
  /**
   * üéØ M√âTODO PRINCIPAL - RESPOSTA INTELIGENTE
   */
  public async generateSmartReply(context: ConversationContext): Promise<{
    response: string
    mlDecision: MLDecision
    tokensUsed: number
  }> {
    
    // üß† ETAPA 1: DETERMINAR COMPLEXIDADE E MODELO
    const complexityAnalysis = this.analyzeComplexity(
      context.messageHistory,
      context.customerContext
    )
    
  const modelToUse = this.selectOptimalModel(complexityAnalysis)
    
    console.log(`ü§ñ Complexidade: ${complexityAnalysis.level} | Modelo: ${modelToUse}`)
    
    // üéØ ETAPA 2: GERAR PROMPT GIGANTESCO PERSONALIZADO
    const megaPrompt = this.promptEngine.generateMegaPrompt(
      context.messageHistory,
      context.customerContext,
      context.banditContext
    )
    
    console.log(`üìã Prompt gerado: ${megaPrompt.length} caracteres`)
    
    // üöÄ ETAPA 3: EXECUTAR GPT COM FALLBACK
  const result = await this.executeWithFallback(
      megaPrompt,
      modelToUse,
      complexityAnalysis
    )

    // P√≥s-processamento determin√≠stico para robustez de UX
  const outboundMsgs = (context.messageHistory || []).filter(m => m.direction === 'outbound')
  const isFirstInteraction = outboundMsgs.length === 0
  // Buscar nome no contexto, que pode estar aninhado
  const customerName: string | undefined = context.customerContext?.name || 
                                           context.customerContext?.info?.name ||
                                           context.customerContext?.info?.info?.name
  const usedNameBefore = Boolean(customerName && outboundMsgs.some(m => new RegExp(`\\b${customerName.replace(/[-/\\^$*+?.()|[\]{}]/g, '\\$&')}\\b`, 'i').test(String(m.content || ''))))
    // Build simple state flags from customer context for deterministic sequencing
    const cc = context.customerContext || {}
    const state = {
      hasName: Boolean(customerName), // Usar o nome encontrado, n√£o cc.name
      hasAddress: Boolean(cc.address),
      hasComplement: typeof cc.complement !== 'undefined',
      hasCep: Boolean(cc.cep),
      hasCity: Boolean(cc.city),
      awaitingConfirmation: Boolean(cc.awaitingConfirmation),
      dataConfirmed: Boolean(cc.dataConfirmed)
    }

    result.response = this.postProcessResponse(
      result.response,
      { isFirstInteraction, customerName, usedNameBefore },
      state
    )
    // Enforce short replies consistently (m√°ximo 2 linhas)
    result.response = this.validateResponseLength(result.response)
    
    // üìä ETAPA 4: REGISTRAR DECIS√ÉO ML
    const mlDecision: MLDecision = {
      modelUsed: result.modelUsed as 'gpt-3.5-turbo' | 'gpt-4o-mini',
      strategy: this.promptEngine['mlConfig'], // Acesso √† config ML
      confidence: complexityAnalysis.confidence,
      reasoning: complexityAnalysis.factors
    }
    
    // üíæ ETAPA 5: SALVAR DECIS√ÉO PARA ANALYTICS
    await this.logMLDecision(context, mlDecision, result.response)
    
    return {
  response: result.response,
      mlDecision,
      tokensUsed: result.tokensUsed
    }
  }
  
  /**
   * üîç AN√ÅLISE DE COMPLEXIDADE INTELIGENTE
   */
  private analyzeComplexity(messageHistory: any[], customerContext: any): {
    level: 'simple' | 'moderate' | 'complex'
    confidence: number
    factors: string[]
    scores: Record<string, number>
  } {
    
    const factors: string[] = []
    const scores: Record<string, number> = {}
    
    // √öltima mensagem do cliente
    const lastMessage = messageHistory.filter(m => m.direction === 'inbound').slice(-1)[0]
    const messageText = lastMessage?.content || ''
    
    // üî• FATORES DE COMPLEXIDADE
    
    // 1. Tamanho da mensagem
    const messageLength = messageText.length
    scores.messageLength = Math.min(messageLength / 200, 1) // 0-1
    if (messageLength > 150) factors.push('mensagem_longa')
    
    // 2. Palavras complexas
    const complexWords = [
      'problema', 'reclama', 'defeito', 'troca', 'devolve', 'cancelar',
      'n√£o gostei', 'estragou', 'jur√≠dico', 'advogado', 'processo',
      'reembolso', 'garantia', 'prazo', 'nota fiscal', 'cupom',
      'desconto', 'promo√ß√£o', 'concorrente', 'comparar'
    ]
    
    const hasComplexWords = complexWords.some(word => 
      messageText.toLowerCase().includes(word)
    )
    scores.complexWords = hasComplexWords ? 1 : 0
    if (hasComplexWords) factors.push('palavras_complexas')
    
    // 3. Hist√≥rico longo
    const conversationLength = messageHistory.length
    scores.conversationLength = Math.min(conversationLength / 20, 1)
    if (conversationLength > 10) factors.push('conversa_longa')
    
    // 4. Obje√ß√µes detectadas
    const objectionPatterns = [
      /muito caro|caro demais|n√£o tenho dinheiro/i,
      /n√£o confio|desconfio|suspeito|golpe/i,
      /demora muito|prazo longo|urgente/i,
      /tamanho errado|n√£o serve|pequeno|grande/i
    ]
    
    const hasObjections = objectionPatterns.some(pattern => 
      pattern.test(messageText)
    )
    scores.objections = hasObjections ? 1 : 0
    if (hasObjections) factors.push('objecoes_detectadas')
    
    // 5. Cliente frustrado
    const frustrationWords = [
      'irritado', 'chateado', 'decepcionado', 'p√©ssimo',
      'horr√≠vel', 'nunca mais', 'cancelar tudo'
    ]
    
    const isFrustrated = frustrationWords.some(word =>
      messageText.toLowerCase().includes(word)
    )
    scores.frustration = isFrustrated ? 1 : 0
    if (isFrustrated) factors.push('cliente_frustrado')
    
    // 6. Contexto do cliente
    scores.customerStage = 0
    if (customerContext?.hasShownInterest) {
      scores.customerStage = 0.3
      factors.push('cliente_interessado')
    }
    if (customerContext?.readyToBuy) {
      scores.customerStage = 0.7
      factors.push('cliente_pronto_comprar')
    }
    
    // 7. Primeira intera√ß√£o
    const isFirstInteraction = conversationLength <= 2
    scores.firstInteraction = isFirstInteraction ? 0.2 : 0
    if (isFirstInteraction) factors.push('primeira_interacao')
    
    // üßÆ C√ÅLCULO FINAL
    const totalScore = Object.values(scores).reduce((sum, score) => sum + score, 0)
    const maxScore = Object.keys(scores).length
    const complexityRatio = totalScore / maxScore
    
    let level: 'simple' | 'moderate' | 'complex'
    if (complexityRatio < 0.3) {
      level = 'simple'
    } else if (complexityRatio < 0.6) {
      level = 'moderate'  
    } else {
      level = 'complex'
    }
    
    const confidence = Math.min(0.5 + complexityRatio, 1)
    
    console.log(`üîç An√°lise de complexidade:`, {
      level,
      confidence: `${(confidence * 100).toFixed(1)}%`,
      scores,
      factors
    })
    
    return { level, confidence, factors, scores }
  }
  
  /**
   * üéØ SELE√á√ÉO INTELIGENTE DE MODELO
   */
  private selectOptimalModel(analysis: any): 'gpt-3.5-turbo' | 'gpt-4o-mini' {
    
    // ‚ö° GPT-3.5 para casos simples (BARATO)
    if (analysis.level === 'simple') {
      console.log('‚ö° GPT-3.5 selecionado: caso simples')
      return 'gpt-3.5-turbo'
    }
    
    // üß† GPT-4 para casos moderados/complexos (INTELIGENTE)
    if (analysis.level === 'complex' || analysis.confidence > 0.7) {
      console.log('üß† GPT-4 selecionado: caso complexo')
      return 'gpt-4o-mini'
    }
    
    // üéØ DECIS√ÉO ML para casos moderados
    // Contexto m√≠nimo v√°lido para o bandit; evite propriedades inexistentes
    const mlDecision = universalBandits.selectBestArm('approach', {
      customerProfile: 'new',
      city: '',
      hasCodeDelivery: false,
      timeOfDay: 'afternoon',
      dayOfWeek: 'weekday',
      conversationStage: 'opening',
      messageCount: 1
    })
    
    const selectedModel = mlDecision?.variant?.includes('gpt-4') ? 'gpt-4o-mini' : 'gpt-3.5-turbo'
    
    console.log(`üéØ ML decidiu: ${selectedModel} (arm: ${mlDecision?.id})`)
    
    return selectedModel
  }
  
  /**
   * üöÄ EXECU√á√ÉO COM FALLBACK INTELIGENTE
   */
  private async executeWithFallback(
    prompt: string,
    primaryModel: string,
    analysis: any
  ): Promise<{
    response: string
    modelUsed: string
    tokensUsed: number
  }> {
    
    try {
      // üéØ TENTATIVA PRINCIPAL
      console.log(`üöÄ Tentando ${primaryModel}...`)
      
      const completion = await this.openai.chat.completions.create({
        model: primaryModel,
        temperature: 0.7,
        max_tokens: 500,
        messages: [
          {
            role: 'system',
            content: prompt
          }
        ]
      })
      
      const response = completion.choices[0]?.message?.content?.trim()
      const tokensUsed = completion.usage?.total_tokens || 0
      
      if (response && response.length > 10) {
        console.log(`‚úÖ ${primaryModel} sucesso: ${response.length} chars`)
        return {
          response,
          modelUsed: primaryModel,
          tokensUsed
        }
      }
      
      throw new Error('Resposta muito curta ou vazia')
      
    } catch (error) {
      const msg = (error as any)?.message || String(error)
      console.error(`‚ùå ${primaryModel} falhou:`, msg)
      
      // üîÑ FALLBACK AUTOM√ÅTICO
      const fallbackModel = primaryModel === 'gpt-4o-mini' ? 'gpt-3.5-turbo' : 'gpt-4o-mini'
      
      console.log(`üîÑ Tentando fallback: ${fallbackModel}`)
      
      try {
        const completion = await this.openai.chat.completions.create({
          model: fallbackModel,
          temperature: 0.8,
          max_tokens: 400,
          messages: [
            {
              role: 'system', 
              content: prompt
            }
          ]
        })
        
        const response = completion.choices[0]?.message?.content?.trim()
        const tokensUsed = completion.usage?.total_tokens || 0
        
        if (response && response.length > 10) {
          console.log(`‚úÖ Fallback ${fallbackModel} sucesso`)
          return {
            response,
            modelUsed: fallbackModel,
            tokensUsed
          }
        }
        
      } catch (fallbackError) {
        const fmsg = (fallbackError as any)?.message || String(fallbackError)
        console.error(`‚ùå Fallback tamb√©m falhou:`, fmsg)
      }
      
      // üÜò FALLBACK FINAL - RESPOSTA ESTRUTURADA
      return {
        response: this.generateEmergencyResponse(analysis),
        modelUsed: 'fallback',
        tokensUsed: 0
      }
    }
  }
  
  /**
   * üÜò RESPOSTA DE EMERG√äNCIA
   */
  private generateEmergencyResponse(analysis: any): string {
    const factors = analysis.factors || []
    
    if (factors.includes('objecoes_detectadas')) {
      return 'Entendo sua preocupa√ß√£o! Nossa Calcinha Lipo tem garantia de 30 dias. Posso esclarecer suas d√∫vidas?'
    }
    
    if (factors.includes('cliente_frustrado')) {
      return 'Pe√ßo desculpas pelo inconveniente. Vou resolver isso agora mesmo. Pode me explicar o que aconteceu?'
    }
    
    if (factors.includes('primeira_interacao')) {
      return 'Oi! Sou a Larissa, gerente comercial da ShapeFit Brasil. Trabalho com a Calcinha Lipo Modeladora.'
    }
    
    return 'Obrigada por entrar em contato!'
  }
  
  /**
   * üìä LOG DE DECIS√ïES ML
   */
  private async logMLDecision(
    context: ConversationContext,
    decision: MLDecision,
    response: string
  ) {
    
    const decisionLog = {
      timestamp: new Date().toISOString(),
      customerId: context.customerId,
      conversationId: context.conversationId,
      modelUsed: decision.modelUsed,
      strategy: decision.strategy,
      confidence: decision.confidence,
      factors: decision.reasoning,
      responseLength: response.length,
      messageCount: context.messageHistory.length
    }
    
    // üìù LOG CONSOLE PARA DEBUG
    console.log('üìä ML Decision Log:', JSON.stringify(decisionLog, null, 2))
    
    // üíæ SALVAR NO BANCO (OPTIONAL)
    try {
      await (prisma as any).mlDecision?.create({
        data: {
          customerId: context.customerId,
          conversationId: context.conversationId,
          modelUsed: decision.modelUsed,
          strategy: JSON.stringify(decision.strategy),
          confidence: decision.confidence,
          factors: JSON.stringify(decision.reasoning),
          responseGenerated: response.substring(0, 500), // Primeira parte
          timestamp: new Date()
        }
      })
    } catch (error) {
      const msg = (error as any)?.message || String(error)
      console.log('‚ö†Ô∏è Erro salvando ML decision (tabela pode n√£o existir):', msg)
    }
    
    // üéØ BROADCAST PARA DASHBOARD
    const g: any = global as any
    if (g && typeof g.broadcast === 'function') {
      g.broadcast('ml-decision', decisionLog)
    }
  }
  
  /**
   * üìà REGISTRAR RESULTADO DA CONVERSA
   */
  public async recordConversationResult(
    conversationId: string,
    result: {
      responded: boolean
      progressed: boolean  
      converted: boolean
      customerSatisfaction?: number
    }
  ) {
    
    // Registra no prompt engine para ML aprender
    this.promptEngine.recordConversationResult({
      responded: result.responded,
      progressed: result.progressed,
      converted: result.converted,
      feedback: result.customerSatisfaction ? `satisfaction:${result.customerSatisfaction}` : 'none'
    })
    
    console.log(`üìà Resultado registrado para conversa ${conversationId}:`, result)
  }

  /**
   * üé≠ GERA√á√ÉO DE RESPOSTA COM ESTRAT√âGIA ADAPTATIVA
   */
  public async generateAdaptiveReply(
    context: ConversationContext,
    strategy: any
  ): Promise<string> {
    console.log(`üé≠ Gerando resposta com estrat√©gia: ${strategy.name}`)
    
    try {
      // Construir prompt adaptado com a estrat√©gia
      const basePrompt = this.buildBasePrompt(context)
      
      // Aplicar modifica√ß√µes da estrat√©gia
      const adaptedPrompt = this.adaptPromptWithStrategy(basePrompt, strategy, context)
      
      // Selecionar modelo baseado na complexidade e estrat√©gia
      const modelToUse = strategy.approach === 'direct' ? 'gpt-3.5-turbo' : 'gpt-4o-mini'
      
      console.log(`ü§ñ Usando modelo: ${modelToUse} para estrat√©gia: ${strategy.approach}`)
      
      // Gerar resposta
      const completion = await this.openai.chat.completions.create({
        model: modelToUse,
        messages: [{ role: 'user', content: adaptedPrompt }],
        max_tokens: 150, // Limite para respostas curtas
        temperature: strategy.tone === 'casual' ? 0.8 : 0.6,
        top_p: 0.9
      })
      
      const response = completion.choices[0]?.message?.content?.trim() || ''
      
  // P√≥s-processamento e valida√ß√£o (regras UX + feminino + 2 linhas)
  const outboundMsgs = (context.messageHistory || []).filter(m => m.direction === 'outbound')
  const isFirstInteraction = outboundMsgs.length === 0
  const customerName: string | undefined = context.customerContext?.name
  const usedNameBefore = Boolean(customerName && outboundMsgs.some(m => new RegExp(`\\b${customerName.replace(/[-/\\^$*+?.()|[\]{}]/g, '\\$&')}\\b`, 'i').test(String(m.content || ''))))

      const cc = context.customerContext || {}
      const state = {
        hasName: Boolean(cc.name),
        hasAddress: Boolean(cc.address),
        hasComplement: typeof cc.complement !== 'undefined',
        hasCep: Boolean(cc.cep),
        hasCity: Boolean(cc.city),
        awaitingConfirmation: Boolean(cc.awaitingConfirmation),
        dataConfirmed: Boolean(cc.dataConfirmed)
      }

      let processed = this.postProcessResponse(response, { isFirstInteraction, customerName, usedNameBefore }, state)
  processed = this.validateResponseLength(processed)

  console.log(`‚úÖ Resposta gerada (${processed.split('\n').length} linhas): "${processed.substring(0, 50)}..."`)

  return processed
      
    } catch (error: any) {
      console.error('‚ùå Erro na gera√ß√£o adaptativa:', error.message)
      return 'N√£o entendi. Pode repetir?'
    }
  }
  
  /**
   * üèóÔ∏è CONSTRUIR PROMPT BASE COM HIST√ìRICO COMPLETO
   */
  private buildBasePrompt(context: ConversationContext): string {
    const lastMessage = context.messageHistory[context.messageHistory.length - 1]?.content || ''
    const customerName = context.customerContext.name || ''
    const city = context.customerContext.city || ''
  const delivery = city ? getDeliveryInfo(city) : undefined
  const outboundCount = context.messageHistory.filter(m => m.direction === 'outbound').length
  const isFirstInteraction = outboundCount === 0
  const hasGreetedBefore = context.messageHistory.some(m => m.direction === 'outbound' && /sou a\s*larissa|shapefit\s*brasil/i.test(String(m.content || '')))
    
    // üìö CONSTRUIR HIST√ìRICO COMPLETO DA CONVERSA
    const conversationHistory = context.messageHistory
      .slice(-40) // √öltimas 40 mensagens para mais contexto
      .map((msg, index) => {
        const direction = msg.direction === 'inbound' ? 'CLIENTE' : 'LARISSA'
        return `${direction}: ${msg.content}`
      })
      .join('\n')
    
  return `Voc√™ √© a Larissa, assistente comercial da ShapeFit Brasil, vendedora especialista em Calcinha Lipo Modeladora.

PRODUTO: Calcinha Lipo Modeladora - Produ√ß√£o Pr√≥pria (Pedro e Luiza)
PRE√áOS OFICIAIS: 
- 2 unidades: R$ 139,90 (PROMO√á√ÉO PRINCIPAL)
- 3 unidades: R$ 179,90 (MELHOR OFERTA)
- 1 unidade: R$ 97,00 (fora da promo√ß√£o)

QUALIDADE:
- Tecido Cetinete de alta compress√£o
- Cintura alta, n√£o marca e nem enrola
- Tamanhos: P/M (34-42) e G/GG (44-50)
- Cores: Preto e Bege

ENTREGA - MUITO IMPORTANTE:
- 70 CIDADES COM PAGAMENTO NA ENTREGA: S√£o Paulo, Rio de Janeiro, Belo Horizonte, Porto Alegre, Salvador, Recife, Fortaleza, Goi√¢nia e regi√µes metropolitanas
- SEMPRE perguntar cidade ANTES de falar sobre pagamento
- Se cidade estiver na lista de pagamento na entrega: "Pagamento NA ENTREGA com nossa equipe (sem taxa/frete)"
- Se cidade N√ÉO estiver: "Entrega via CORREIOS com pagamento ANTECIPADO"
- Nunca prometa pagamento na entrega sem verificar se a cidade est√° na lista

DIFERENCIAIS:
- Produ√ß√£o exclusiva nossa
- N√£o temos site/insta - venda humanizada s√≥ no WhatsApp
- Sem trocas (quest√£o de higiene/seguran√ßa)
- Pode verificar qualidade antes de pagar (s√≥ nas cidades com pagamento na entrega)

SINAIS DE CONTEXTO (n√£o escreva isso para o cliente, use apenas para decidir o tom):
- FIRST_INTERACTION: ${isFirstInteraction ? 'SIM' : 'N√ÉO'}
- HAS_GREETED_BEFORE: ${hasGreetedBefore ? 'SIM' : 'N√ÉO'}
- CUSTOMER_NAME: ${customerName || 'desconhecido'}

APRESENTA√á√ÉO INICIAL:
- OBRIGAT√ìRIO: Se FIRST_INTERACTION=SIM, SEMPRE inicie com: "Oi! Sou a Larissa, gerente comercial da ShapeFit Brasil. Trabalho com a Calcinha Lipo Modeladora, que modela o corpo e real√ßa suas curvas."
- IMPORTANTE: A apresenta√ß√£o DEVE incluir quem voc√™ √© (GERENTE COMERCIAL), empresa, produto - N√ÉO terminar com pergunta "como posso ajudar"
- Se FIRST_INTERACTION=N√ÉO, n√£o se apresente novamente e n√£o use sauda√ß√µes como "Oi" ou "Ol√°" no come√ßo
- N√ÉO repita o nome do cliente se j√° disse antes

COMPORTAMENTO (tom humano e vendas):
- Seja CONSULTIVA e EDUCATIVA (explique benef√≠cios do produto)
- SEMPRE apresente diferenciais e qualidade quando perguntada sobre produto
- Se cliente s√≥ cumprimenta ("oi", "ol√°"), apresente o produto com benef√≠cios
- Adapte o tom ao cliente, mas sempre mantenha o foco em vendas
- Explique como a calcinha modela, levanta o bumbum e afina a cintura
- Mencione o tecido de compress√£o e qualidade superior
- SEM EMOJIS - linguagem natural e profissional
- Linguagem SEMPRE no feminino (ex.: interessada, pronta, bem-vinda, obrigada)

FLUXO DE FECHAMENTO (quando cliente confirma compra):
IMPORTANTE: Pedir UM DADO POR VEZ, nunca m√∫ltiplos dados numa mensagem!

SEQU√äNCIA OBRIGAT√ìRIA:
1. Se n√£o tem NOME: pedir apenas "Qual seu nome completo?"
2. Se n√£o tem RUA+N√öMERO: pedir apenas "Qual seu endere√ßo com rua e n√∫mero?"
3. Se n√£o tem COMPLEMENTO: perguntar apenas "Tem complemento? (apartamento, condom√≠nio, etc.)"
4. Se n√£o tem CEP: pedir apenas "Qual o CEP?"
5. Se n√£o tem CIDADE+UF: pedir apenas "Qual cidade e estado?"
6. **CONFIRMA√á√ÉO OBRIGAT√ìRIA**: Quando tiver TODOS os dados, SEMPRE confirmar:
   "Vou confirmar seus dados:
   Nome: [NOME]
   Produto: [QUANTIDADE] Calcinha(s) Lipo [COR]
   Endere√ßo: [ENDERE√áO COMPLETO]
   [TIPO DE PAGAMENTO]
   
   Est√° tudo correto? (Digite 'sim' para confirmar)"

7. S√≥ AP√ìS confirma√ß√£o do cliente: "Perfeito! Pedido confirmado, [NOME]! Vou agendar sua entrega e te envio os detalhes em breve. Obrigada pela compra!"

REGRA CR√çTICA: Se falta algum dado da lista acima, pedir APENAS ESSE DADO espec√≠fico na pr√≥xima mensagem.
NUNCA pedir m√∫ltiplos dados numa mensagem!
NUNCA pular etapas da sequ√™ncia!
NUNCA finalizar sem confirma√ß√£o do cliente!
Ap√≥s confirma√ß√£o, SEMPRE finalizar com informa√ß√£o sobre pr√≥ximos passos!

DADOS OBRIGAT√ìRIOS PARA FINALIZAR VENDA (coletar UM POR VEZ):
1. Nome completo 
2. Rua/Av + n√∫mero   
3. Complemento (se tiver)
4. CEP 
5. Cidade + UF 
6. Produto + quantidade + cor confirmados

REGRA CR√çTICA: Pedir apenas 1 dado por mensagem!
Se falta algum dado da lista, pedir SOMENTE esse dado.
NUNCA pedir m√∫ltiplos dados numa mensagem!

OBJE√á√ïES PRINCIPAIS:
- "T√° caro": Tecido cetinete de alt√≠ssima qualidade, vale cada centavo
- "Se n√£o gostar": (Pagamento na entrega) pode verificar antes de pagar / (Correios) qualidade garantida
- "Tem troca": N√£o trocamos por higiene/seguran√ßa
- "Enrola/marca": N√£o enrola nem marca pelo tecido de alta compress√£o

=== HIST√ìRICO COMPLETO DA CONVERSA ===
${conversationHistory}

=== CONTEXTO DO CLIENTE ===
${customerName ? `NOME: ${customerName}` : 'Nome: n√£o informado'}
${city ? `CIDADE: ${city}` : 'Cidade: n√£o informada'}
${delivery ? `ENTREGA DETECTADA: ${delivery.type === 'COD' ? 'Pagamento na entrega (sem taxa/frete nas 70 cidades)' : 'Correios com pagamento antecipado'}` : 'ENTREGA DETECTADA: n√£o informada'}
${context.customerContext.size ? `TAMANHO: ${context.customerContext.size}` : ''}
${context.customerContext.color ? `COR: ${context.customerContext.color}` : ''}
${context.customerContext.address ? `ENDERE√áO: ${context.customerContext.address}` : ''}
${context.customerContext.complement ? `COMPLEMENTO: ${context.customerContext.complement}` : ''}
${context.customerContext.cep ? `CEP: ${context.customerContext.cep}` : ''}
${context.customerContext.awaitingConfirmation ? `üîî AGUARDANDO CONFIRMA√á√ÉO DOS DADOS` : ''}
${context.customerContext.dataConfirmed ? `‚úÖ DADOS CONFIRMADOS PELO CLIENTE` : ''}

√öLTIMA MENSAGEM DO CLIENTE: "${lastMessage}"

REGRAS CR√çTICAS:
1. Se √© PRIMEIRO CONTATO (hist√≥rico vazio), SEMPRE inicie com: "Oi! Sou a Larissa, gerente comercial da ShapeFit Brasil."
2. Se N√ÉO √© primeiro contato, n√£o se apresente novamente
3. NUNCA repita cumprimentos se j√° cumprimentou antes
4. Um dado por vez: nome ‚Üí endere√ßo ‚Üí complemento ‚Üí CEP ‚Üí cidade ‚Üí confirma√ß√£o
5. NUNCA pe√ßa "endere√ßo completo", apenas "Qual seu endere√ßo com rua e n√∫mero?"

IMPORTANTE: 
- Mantenha conversa NATURAL e objetiva
- N√ÉO force fechamento de vendas
- Responda o que foi perguntado
- Seja consultiva, n√£o vendedora agressiva
- M√°ximo 2 linhas por resposta (curto e direto)
- SEM EMOJIS - linguagem profissional e natural
- ANALISE TODO O HIST√ìRICO DA CONVERSA antes de responder
- Se √© primeiro contato, SEMPRE se apresente como Larissa da ShapeFit Brasil
- Se o cliente j√° informou dados (nome, quantidade, cor), N√ÉO pe√ßa novamente
- NUNCA pe√ßa m√∫ltiplos dados numa mensagem
- SEQU√äNCIA: nome ‚Üí endere√ßo ‚Üí complemento ‚Üí CEP ‚Üí cidade ‚Üí confirma√ß√£o ‚Üí finaliza√ß√£o
- Para complemento: pergunte se tem, se n√£o tiver pule para pr√≥ximo dado

CHECKLIST ANTES DE FINALIZAR PEDIDO:
- Tenho o nome completo? Se n√£o, pedir APENAS o nome.
- Tenho rua + n√∫mero? Se n√£o, pedir APENAS o endere√ßo.
- Perguntei sobre complemento? Se n√£o, perguntar APENAS sobre complemento.
- Tenho o CEP? Se n√£o, pedir APENAS o CEP.
- Tenho cidade + estado? Se n√£o, pedir APENAS cidade e estado.
- Se tenho TODOS os dados: fazer CONFIRMA√á√ÉO obrigat√≥ria antes de finalizar
- S√≥ finalizar AP√ìS cliente confirmar dados com "sim", "correto", etc.

REGRA ABSOLUTA: UM DADO POR MENSAGEM! 
- NUNCA pe√ßa "endere√ßo completo"
- NUNCA pe√ßa m√∫ltiplos dados numa frase
- SEMPRE pe√ßa apenas o pr√≥ximo dado necess√°rio da sequ√™ncia
- Se falta endere√ßo: "Qual seu endere√ßo com rua e n√∫mero?"
- Se falta complemento: "Tem complemento? (apartamento, etc.)"
- Se falta CEP: "Qual o CEP?"
- NUNCA diga "endere√ßo completo" ou similares!
- N√ÉO cumprimente o cliente novamente se j√° cumprimentou
- N√ÉO termine mensagens com "como posso ajudar" ou "em que posso te ajudar"
- S√≥ finalizar quando tiver TODOS os dados!

Responda de forma natural, mantendo o contexto da conversa anterior.`
  }
  
  /**
   * üéØ ADAPTAR PROMPT COM ESTRAT√âGIA
   */
  private adaptPromptWithStrategy(basePrompt: string, strategy: any, context: ConversationContext): string {
    const modifications = strategy.promptModifications.join('\n')
    
    return `${basePrompt}

=== ESTRAT√âGIA ATIVA: ${strategy.name.toUpperCase()} ===
${modifications}

REGRAS CR√çTICAS DE RESPOSTA:
- M√ÅXIMO 2 LINHAS (nunca mais que isso)
- Tom: ${strategy.tone}
- Abordagem: ${strategy.approach}
- Estilo: ${strategy.messageStyle}

CONTEXTO ESPEC√çFICO:
- Cidade: ${context.customerContext.city || 'n√£o informada'}
- Perfil: ${context.banditContext.customerProfile || 'novo'}
- Est√°gio: ${context.banditContext.conversationStage || 'inicial'}
- Mensagens: ${context.messageHistory.length}

IMPORTANTE: Resposta deve ser direta, √∫til e NUNCA passar de 2 linhas.`
  }
  
  /**
   * ‚úÇÔ∏è VALIDAR E AJUSTAR TAMANHO DA RESPOSTA
   */
  private validateResponseLength(response: string): string {
    const lines = response.split('\n').filter(line => line.trim().length > 0)
    
    if (lines.length > 2) {
      console.log(`‚úÇÔ∏è Truncando resposta de ${lines.length} para 2 linhas`)
      return lines.slice(0, 2).join('\n')
    }
    
    return response
  }

  /**
   * üîß P√≥s-processamento determin√≠stico para garantir regras de UX
   */
  private postProcessResponse(
    response: string,
    opts: { isFirstInteraction: boolean; customerName?: string; usedNameBefore?: boolean },
    state?: { hasName?: boolean; hasAddress?: boolean; hasComplement?: boolean; hasCep?: boolean; hasCity?: boolean; awaitingConfirmation?: boolean; dataConfirmed?: boolean }
  ): string {
    if (!response) return response
    let r = response.trim()

    // 1) Nunca pedir "endere√ßo completo"
    r = this.avoidEnderecoCompleto(r)

  // 2) Limpar emojis e frases desnecess√°rias o quanto antes
    r = this.removeEmojisAndAnnoyingPhrases(r)

  // 3) Garantir UM dado por mensagem (heur√≠stica por palavras-chave)
    r = this.enforceOneFieldOnly(r)

    // 5) Enforce sequ√™ncia determin√≠stica dos dados APENAS se GPT n√£o est√° seguindo ordem
    //    Importante: n√£o sobrescrever a apresenta√ß√£o da primeira mensagem
    if (!opts.isFirstInteraction && state && this.needsSequenceEnforcement(r, state)) {
      r = this.enforceDataSequence(r, state)
    }

    // 6) Evitar uso for√ßado do nome do cliente em perguntas de dados
    if (opts.customerName) {
      r = this.sanitizeNameInDataQuestions(r, opts.customerName)
    }

    // 6) For√ßar linguagem no feminino em termos comuns
  r = this.ensureFeminineLanguage(r)

    // 7) Cumprimento: garantir apresenta√ß√£o no primeiro contato e evitar repetir depois
  r = this.fixGreeting(r, opts)

    return r
  }

  private fixGreeting(response: string, opts: { isFirstInteraction: boolean, customerName?: string, usedNameBefore?: boolean }): string {
    let r = response
    const greetingRegex = /^(ol[√°a]|oi|boa\s*(tarde|noite|dia))[,!\s]*([A-Za-z√Ä-√ø'`\- ]+)?[,!\s]*/i
    
    if (opts.isFirstInteraction) {
      // Garantir apresenta√ß√£o completa da Larissa como GERENTE COMERCIAL
      if (!/sou a\s*larissa/i.test(r)) {
        const completeIntro = 'Oi! Sou a Larissa, gerente comercial da ShapeFit Brasil. Trabalho com a Calcinha Lipo Modeladora, que modela o corpo e real√ßa suas curvas.'
        r = completeIntro
      }
      // Se j√° tem apresenta√ß√£o mas n√£o menciona GERENTE COMERCIAL, corrigir
      else if (!/gerente\s+comercial/i.test(r)) {
        r = r.replace(/assistente\s+comercial/i, 'gerente comercial')
      }
      // Se j√° tem apresenta√ß√£o mas n√£o menciona produto, adicionar
      else if (!/calcinha|lipo|modela/i.test(r)) {
        const lines = r.split('\n')
        lines[0] = lines[0] + ' Trabalho com a Calcinha Lipo Modeladora, que modela o corpo e real√ßa suas curvas.'
        r = lines.join('\n')
      }
    } else {
      // Remover cumprimentos repetidos e nome do cliente no come√ßo
      r = r.replace(greetingRegex, '')
      r = r.trim()

      // Remover autoapresenta√ß√µes em intera√ß√µes cont√≠nuas de forma mais robusta
      const introPatterns = [
        /oi!\s*sou a\s*larissa[^.?!]*[.?!]?\s*/gi,
        /sou a\s*larissa[^.?!]*[.?!]?\s*/gi,
        /meu nome √©\s*larissa[^.?!]*[.?!]?\s*/gi,
        /(assistente|gerente)\s+comercial[^.?!]*[.?!]?\s*/gi,
        /da\s*shapefit\s*brasil[^.?!]*[.?!]?\s*/gi,
        /trabalho\s+com\s+a\s+calcinha\s+lipo[^.?!]*[.?!]?\s*/gi,
        /que\s+modela\s+o\s+corpo[^.?!]*[.?!]?\s*/gi
      ]
      
      introPatterns.forEach(pattern => {
        r = r.replace(pattern, ' ')
      })
      
      r = r.replace(/\s{2,}/g, ' ').trim()

      // Personalizar com nome do cliente uma √∫nica vez, de forma natural (n√£o adicionar em perguntas de dados)
      const isDataAsk = /(nome completo|endere[√ßc]o|rua|n[u√∫]mero|complemento|apartamento|cep|cidade|estado|uf)/i.test(r)
      if (!isDataAsk && opts.customerName && !opts.usedNameBefore) {
        const softOpeners = [
          'Perfeito',
          'Certo',
          'Legal',
          'Combinado'
        ]
        const opener = softOpeners[Math.floor(Math.random()*softOpeners.length)]
        // S√≥ adiciona o nome se a frase n√£o come√ßar com ele j√°
        if (!new RegExp(`^${opts.customerName}\\b`, 'i').test(r) && r.length > 0) {
          r = `${opener}, ${opts.customerName}! ${r}`
        }
      }

      // Se n√£o temos nome e estamos pedindo o nome, manter pergunta direta sem apresenta√ß√£o
      if (!opts.customerName && /(qual\s*seu\s*nome\s*completo|preciso\s*do\s*seu\s*nome\s*completo)/i.test(r)) {
        r = 'Qual seu nome completo?'
      }
    }
    return r
  }

  private avoidEnderecoCompleto(response: string): string {
    let r = response
    // Substituir pedidos vagos por direcionados (rua e n√∫mero)
    if (/endere[√ßc]o\s*completo|endere[√ßc]o\s*inteiro/i.test(r)) {
      r = r.replace(/.*endere[√ßc]o.*completo.*$/i, 'Pode me informar seu endere√ßo com rua e n√∫mero?')
    }
    // Evitar listar muitos campos de uma vez
    if (/(rua|n[u√∫]mero).*(complemento|cep|cidade|estado)/i.test(r)) {
      r = 'Pode me informar seu endere√ßo com rua e n√∫mero?'
    }
    return r
  }

  private enforceOneFieldOnly(response: string): string {
    let r = response
    const fields = [
      { key: 'rua_numero', regex: /(rua|avenida|av\.|r\.|n[u√∫]mero)/i, prompt: 'Pode me informar seu endere√ßo com rua e n√∫mero?' },
      { key: 'complemento', regex: /(complemento|apartamento|apto|bloco|casa|condom[i√≠]nio|torre)/i, prompt: 'Tem complemento? (apartamento, condom√≠nio, etc.)' },
      { key: 'cep', regex: /(cep)/i, prompt: 'Qual o CEP?' },
      { key: 'cidade', regex: /(cidade|estado|uf)/i, prompt: 'Qual cidade e estado?' }
    ]

    // Se a resposta cont√©m men√ß√£o a 2 ou mais tipos de campos, reduzir para o primeiro da lista
    const matched = fields.filter(f => f.regex.test(r))
    if (matched.length >= 2) {
      r = matched[0].prompt
    }
    return r
  }

  private needsSequenceEnforcement(response: string, state: { hasName?: boolean; hasAddress?: boolean; hasComplement?: boolean; hasCep?: boolean; hasCity?: boolean }): boolean {
    // S√≥ for√ßar sequ√™ncia se GPT est√° pedindo dado fora de ordem ou m√∫ltiplos dados
    const isAskingMultipleFields = (response.match(/(nome|endere[√ßc]o|rua|complemento|cep|cidade)/gi) || []).length > 1
    
    // Se est√° pedindo nome mas j√° tem nome, precisa de enforcement
    const askingName = /nome.*completo|qual.*nome/i.test(response)
    const wrongNameAsk = askingName && Boolean(state.hasName)
    
    return isAskingMultipleFields || wrongNameAsk
  }

  private enforceDataSequence(response: string, state: { hasName?: boolean; hasAddress?: boolean; hasComplement?: boolean; hasCep?: boolean; hasCity?: boolean; awaitingConfirmation?: boolean; dataConfirmed?: boolean }): string {
    const hasName = Boolean(state.hasName)
    const hasAddress = Boolean(state.hasAddress)
    const hasComplement = Boolean(state.hasComplement)
    const hasCep = Boolean(state.hasCep)
    const hasCity = Boolean(state.hasCity)

    // Determine pr√≥ximo dado necess√°rio
    if (!hasName) return 'Qual seu nome completo?'
    if (!hasAddress) return 'Pode me informar seu endere√ßo com rua e n√∫mero?'
    if (!hasComplement) return 'Tem complemento? (apartamento, condom√≠nio, etc.)'
    if (!hasCep) return 'Qual o CEP?'
    if (!hasCity) return 'Qual cidade e estado?'

    // Se tudo preenchido, deixa a resposta seguir (confirma√ß√£o ser√° conduzida pela l√≥gica do modelo/fluxo)
    return response
  }

  private sanitizeNameInDataQuestions(response: string, customerName: string): string {
    let r = response
    const dataAskRegex = /(nome completo|endere[√ßc]o|rua|n[u√∫]mero|complemento|apartamento|cep|cidade|estado|uf)/i
    if (dataAskRegex.test(r)) {
      // Remover padr√µes ", Nome" ou "Nome," e uso isolado do nome no fim
      const nameEsc = customerName.replace(/[-/\\^$*+?.()|[\]{}]/g, '\\$&')
      r = r.replace(new RegExp(`[,\n\s]*${nameEsc}[.!?]?$`, 'i'), '')
      r = r.replace(new RegExp(`^\s*${nameEsc}[,\s:]+`, 'i'), '')
      r = r.replace(new RegExp(`\b${nameEsc}\b`, 'g'), '').replace(/\s{2,}/g, ' ').trim()
    }
    return r
  }

  private ensureFeminineLanguage(response: string): string {
    let r = response

    // Helper to preserve capitalization of first letter
    const replacePreserveCase = (text: string, pattern: RegExp, replacement: string) => {
      return text.replace(pattern, (match) => {
        const isCapitalized = match[0] === match[0].toUpperCase()
        if (!isCapitalized) return replacement
        return replacement.charAt(0).toUpperCase() + replacement.slice(1)
      })
    }

    // Obrigado -> Obrigada
    r = replacePreserveCase(r, /\bobrigado\b/gi, 'obrigada')
    // Bem-vindo -> Bem-vinda (aceita com espa√ßo ou h√≠fen)
    r = replacePreserveCase(r, /\bbem[\- ]vindo\b/gi, 'bem-vinda')
    // Interessado -> Interessada
    r = replacePreserveCase(r, /\binteressado\b/gi, 'interessada')

    // "pronto" √© tricky (evitar mudar "pedido pronto"). Trocar quando relacionado √† pessoa
    // Casos: "se estiver pronto", "quando estiver pronto", "t√° pronto?", "est√° pronto"
    r = r.replace(/\b(se|quando|se\s+estiver|quando\s+estiver|est(a|√°)|t(a|√°))\s+pronto\b/gi, (m) => m.replace(/pronto/i, (mm) => mm[0] === mm[0].toUpperCase() ? 'Pronta' : 'pronta'))

    return r
  }

  private removeEmojisAndAnnoyingPhrases(response: string): string {
    let r = response
    
    // Remover emojis
    r = r.replace(/[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/gu, '')
    
    // Remover frases desnecess√°rias no final
    r = r.replace(/[.!]*\s*(em que posso te ajudar|como posso te ajudar|como posso ajudar|posso te ajudar)\??[.!]*$/gi, '')
    r = r.replace(/[.!]*\s*(em que mais posso ajudar|como mais posso ajudar)\??[.!]*$/gi, '')
    
    // Limpar espa√ßos duplos e pontua√ß√£o duplicada
    r = r.replace(/\s+/g, ' ').replace(/[.!]{2,}/g, '.').trim()
    
    // Garantir que termine com ponto se for afirma√ß√£o
    if (r && !r.match(/[.!?]$/)) {
      r += '.'
    }
    
    return r
  }
}

// üéØ FUN√á√ÉO WRAPPER PARA COMPATIBILIDADE
export async function generateBotReply(
  conversationId: string,
  messageText: string,
  options: any = {}
): Promise<string> {
  
  try {
    const responder = new SmartGptResponder()
    
    // Buscar hist√≥rico e contexto
    const messageHistory = await getMessageHistory(conversationId)
    const customerContext = options.customerContext || {}
    const banditContext = options.banditContext || {}
    
    const context: ConversationContext = {
      customerId: options.customerId || 'unknown',
      conversationId,
      messageHistory: [...messageHistory, {
        direction: 'inbound',
        content: messageText,
        createdAt: new Date()
      }],
      customerContext,
      banditContext
    }
    
    // üéØ APLICAR ESTRAT√âGIA ADAPTATIVA
    let result: any
    if (options.adaptiveStrategy) {
      console.log(`üé≠ Aplicando estrat√©gia: ${options.adaptiveStrategy.name}`)
      const response = await responder.generateAdaptiveReply(context, options.adaptiveStrategy)
      result = { response, mlDecision: { modelUsed: 'gpt-3.5-turbo' }, tokensUsed: 0 }
    } else {
      result = await responder.generateSmartReply(context)
    }
    
    console.log(`üéØ Smart GPT Response: ${result.response.length} chars, Model: ${result.mlDecision?.modelUsed || 'unknown'}`)
    
    return result.response
    
  } catch (error: any) {
    console.error('‚ùå Erro no Smart GPT Responder:', error.message)
    
    // Fallback para fun√ß√£o original se houver
    try {
      const { generateBotReply: originalFunction } = await import('./gptResponder')
      return originalFunction(conversationId, messageText, options)
    } catch {
      return 'N√£o entendi. Pode repetir?'
    }
  }
}

// üîç HELPER: BUSCAR HIST√ìRICO DE MENSAGENS
async function getMessageHistory(conversationId: string): Promise<any[]> {
  try {
    const messages = await (prisma as any).message.findMany({
      where: { conversationId },
      orderBy: { createdAt: 'asc' },
  take: 80 // Aumentado para incluir mais contexto da conversa
    })
    
    return messages || []
  } catch (error: any) {
    console.error('‚ùå Erro buscando hist√≥rico:', error.message)
    return []
  }
}

export default SmartGptResponder

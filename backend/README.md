# ğŸ® Nexus Gaming Intelligence - Backend Completo

Plataforma completa de inteligÃªncia para Facebook Ads com anÃ¡lise preditiva, scraping automatizado e machine learning.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [Uso](#uso)
- [API Endpoints](#api-endpoints)
- [Monitoramento](#monitoramento)
- [Desenvolvimento](#desenvolvimento)
- [ProduÃ§Ã£o](#produÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

O backend Nexus Gaming Intelligence Ã© uma soluÃ§Ã£o completa que combina:

- **Node.js/Express**: API principal com autenticaÃ§Ã£o JWT
- **PostgreSQL**: Banco de dados principal
- **Redis**: Cache e sistema de filas
- **Python ML Service**: AnÃ¡lise preditiva e machine learning
- **Python Scraper Service**: Web scraping inteligente
- **Docker**: OrquestraÃ§Ã£o completa de serviÃ§os

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â”€â”€â”€â”€â”‚   Backend API   â”‚â”€â”€â”€â”€â”‚   PostgreSQL    â”‚
â”‚   (React)       â”‚    â”‚   (Node.js)     â”‚    â”‚   Database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚     Redis       â”‚
                       â”‚ (Cache + Queue) â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   ML Service    â”‚        â”‚ Scraper Service â”‚
         â”‚   (Python)      â”‚        â”‚   (Python)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ PrÃ©-requisitos

### Docker (Recomendado)
- Docker Engine 20.10+
- Docker Compose 2.0+

### InstalaÃ§Ã£o Local
- Node.js 18+
- Python 3.11+
- PostgreSQL 15+
- Redis 7+

## ğŸš€ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: Docker (Recomendado)

1. **Clone o repositÃ³rio:**
```bash
git clone <repository-url>
cd BACKEND_FODAO
```

2. **Configure as variÃ¡veis de ambiente:**
```bash
cp .env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

3. **Inicie todos os serviÃ§os:**
```bash
docker-compose up -d
```

4. **Aguarde a inicializaÃ§Ã£o completa:**
```bash
# Monitore os logs
docker-compose logs -f

# Verifique o status dos serviÃ§os
docker-compose ps
```

### OpÃ§Ã£o 2: InstalaÃ§Ã£o Local

1. **Backend Principal:**
```bash
# Instalar dependÃªncias
npm install

# Configurar banco
npm run prisma:generate
npm run prisma:push
npm run seed

# Iniciar em desenvolvimento
npm run dev
```

2. **ML Service:**
```bash
cd ml-service
pip install -r requirements.txt
python main.py
```

3. **Scraper Service:**
```bash
cd scraper-service
pip install -r requirements.txt
# Instalar Playwright browsers
playwright install chromium
python main.py
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Copie `.env.example` para `.env` e configure:

```env
# Backend
NODE_ENV=development
PORT=3001

# Database
DATABASE_URL="postgresql://nexus_user:nexus_password@localhost:5432/nexus_db?schema=public"

# Redis
REDIS_URL="redis://localhost:6379"

# JWT
JWT_SECRET="seu-jwt-secret-super-seguro"
JWT_EXPIRES_IN="7d"

# Facebook API
FACEBOOK_ACCESS_TOKEN="seu-facebook-token"
FACEBOOK_AD_ACCOUNT_ID="act_sua-conta-id"
FACEBOOK_APP_ID="seu-app-id"
FACEBOOK_APP_SECRET="seu-app-secret"

# Kiwify API
KIWIFY_CLIENT_ID="seu-kiwify-client-id"
KIWIFY_CLIENT_SECRET="seu-kiwify-client-secret"

# Ideogram API
IDEOGRAM_API_KEY="sua-ideogram-api-key"

# OpenAI (para chat NEXUS)
OPENAI_API_KEY="sua-openai-api-key"

# Admin User
ADMIN_EMAIL="alexvinitius@gmail.com"
ADMIN_PASSWORD="admin123456"
```

### ConfiguraÃ§Ã£o dos ServiÃ§os Python

Os serviÃ§os ML e Scraper sÃ£o configurados automaticamente via variÃ¡veis de ambiente no docker-compose.

## ğŸ® Uso

### 1. Verificar Status dos ServiÃ§os

```bash
# Health check geral
curl http://localhost:3001/health

# Status da API
curl http://localhost:3001/api/status

# ML Service
curl http://localhost:8001/health

# Scraper Service
curl http://localhost:8002/health
```

### 2. AutenticaÃ§Ã£o

```bash
# Registrar usuÃ¡rio
curl -X POST http://localhost:3001/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "usuario@exemplo.com",
    "password": "senha123",
    "name": "Nome do UsuÃ¡rio"
  }'

# Login
curl -X POST http://localhost:3001/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "usuario@exemplo.com",
    "password": "senha123"
  }'
```

### 3. Usar APIs (com token JWT)

```bash
# Obter campanhas
curl -H "Authorization: Bearer SEU_JWT_TOKEN" \
  http://localhost:3001/api/campaigns

# Iniciar scraping
curl -X POST http://localhost:3001/api/scraping/scrape \
  -H "Authorization: Bearer SEU_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "niche": "traicao",
    "ad_type": "GREY",
    "max_results": 20
  }'

# AutomaÃ§Ã£o completa
curl -X POST http://localhost:3001/api/scraping/automation/complete \
  -H "Authorization: Bearer SEU_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "niche": "emagrecimento",
    "ad_type": "GREY",
    "investment": 500
  }'
```

## ğŸ“Š API Endpoints

### AutenticaÃ§Ã£o (`/api/auth`)
- `POST /register` - Registrar usuÃ¡rio
- `POST /login` - Login
- `GET /profile` - Obter perfil
- `PUT /profile` - Atualizar perfil
- `PUT /api-config` - Configurar APIs
- `PUT /change-password` - Alterar senha
- `POST /logout` - Logout
- `GET /verify` - Verificar token

### Campanhas (`/api/campaigns`)
- `GET /` - Listar campanhas
- `POST /` - Criar campanha
- `GET /:id` - Obter campanha
- `PUT /:id` - Atualizar campanha
- `DELETE /:id` - Deletar campanha
- `PUT /:id/metrics` - Atualizar mÃ©tricas
- `GET /:id/analytics` - Obter analytics

### Scraping (`/api/scraping`)
- `POST /scrape` - Iniciar scraping
- `GET /job/:jobId/status` - Status do job
- `GET /results` - Listar resultados
- `GET /results/:id` - Obter resultado
- `DELETE /results/:id` - Deletar resultado
- `POST /automation/complete` - AutomaÃ§Ã£o completa
- `GET /automation/:jobId/status` - Status automaÃ§Ã£o
- `GET /automation/history` - HistÃ³rico

### Facebook API (`/api/facebook`)
- `GET /test` - Testar conexÃ£o
- `GET /campaigns` - Obter campanhas do Facebook
- `GET /ads` - Obter anÃºncios
- `POST /kiwify/oauth` - OAuth Kiwify
- `GET /ideogram/test` - Testar Ideogram

### ML Service (`http://localhost:8001`)
- `POST /predict` - Fazer prediÃ§Ã£o
- `POST /train` - Treinar modelo
- `GET /models` - Listar modelos
- `GET /health` - Health check

### Scraper Service (`http://localhost:8002`)
- `POST /scrape` - Scraping de anÃºncios
- `GET /niches` - Listar nichos disponÃ­veis
- `POST /analyze-competitor` - Analisar concorrente
- `GET /health` - Health check

## ğŸ“ˆ Monitoramento

### Logs

```bash
# Logs do backend
docker-compose logs -f backend

# Logs do ML service
docker-compose logs -f ml-service

# Logs do scraper service
docker-compose logs -f scraper-service

# Logs de todos os serviÃ§os
docker-compose logs -f
```

### MÃ©tricas

```bash
# Status das filas
curl http://localhost:3001/api/status

# Modelos ML disponÃ­veis
curl http://localhost:8001/models

# Nichos de scraping disponÃ­veis
curl http://localhost:8002/niches
```

### Health Checks

Todos os serviÃ§os possuem health checks configurados:

- Backend: `http://localhost:3001/health`
- ML Service: `http://localhost:8001/health`
- Scraper Service: `http://localhost:8002/health`

## ğŸ‘¨â€ğŸ’» Desenvolvimento

### Estrutura do Projeto

```
BACKEND_FODAO/
â”œâ”€â”€ src/                    # Backend principal (Node.js)
â”‚   â”œâ”€â”€ config/            # ConfiguraÃ§Ãµes (DB, Redis, Logger)
â”‚   â”œâ”€â”€ controllers/       # Controllers da API
â”‚   â”œâ”€â”€ middleware/        # Middlewares (Auth, Error, Logging)
â”‚   â”œâ”€â”€ routes/           # Rotas da API
â”‚   â”œâ”€â”€ services/         # ServiÃ§os (Cache, Queue, Logger)
â”‚   â”œâ”€â”€ types/            # Tipos TypeScript
â”‚   â””â”€â”€ server.ts         # Servidor principal
â”œâ”€â”€ ml-service/           # ServiÃ§o ML (Python)
â”‚   â”œâ”€â”€ main.py          # API FastAPI
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ scraper-service/      # ServiÃ§o Scraping (Python)
â”‚   â”œâ”€â”€ main.py          # API FastAPI + Playwright
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ prisma/              # Schema do banco
â”œâ”€â”€ scripts/             # Scripts de seed
â””â”€â”€ docker-compose.yml   # OrquestraÃ§Ã£o Docker
```

### Scripts DisponÃ­veis

```bash
# Backend
npm run dev              # Desenvolvimento
npm run build           # Build para produÃ§Ã£o
npm run start           # Iniciar produÃ§Ã£o
npm run prisma:generate # Gerar cliente Prisma
npm run prisma:push     # Aplicar schema
npm run seed            # Popular banco

# Docker
npm run docker:build    # Build das imagens
npm run docker:up       # Subir serviÃ§os
npm run docker:down     # Parar serviÃ§os
```

### Adicionando Novos Endpoints

1. **Controller**: Crie em `src/controllers/`
2. **Route**: Adicione em `src/routes/`
3. **Types**: Defina em `src/types/`
4. **Middleware**: Se necessÃ¡rio, em `src/middleware/`

### Adicionando Novos Modelos ML

1. Edite `ml-service/main.py`
2. Adicione lÃ³gica de treinamento
3. Configure novos endpoints se necessÃ¡rio

## ğŸš€ ProduÃ§Ã£o

### Build e Deploy

```bash
# Build das imagens
docker-compose build

# Deploy em produÃ§Ã£o
docker-compose -f docker-compose.yml up -d
```

### ConfiguraÃ§Ãµes de ProduÃ§Ã£o

1. **Environment**: Defina `NODE_ENV=production`
2. **SSL**: Configure certificados SSL
3. **Reverse Proxy**: Use nginx/caddy na frente
4. **Monitoramento**: Configure logs externos
5. **Backups**: Configure backup automÃ¡tico do PostgreSQL

### Exemplo nginx.conf

```nginx
server {
    listen 80;
    server_name api.nexusgaming.com;

    location / {
        proxy_pass http://localhost:3001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

## ğŸ› SoluÃ§Ã£o de Problemas

### Problemas Comuns

1. **Porta jÃ¡ em uso**: Altere as portas no docker-compose.yml
2. **Erro de permissÃ£o**: Execute com sudo ou configure Docker sem sudo
3. **Banco nÃ£o conecta**: Verifique se PostgreSQL estÃ¡ rodando
4. **Browser scraper falha**: Instale dependÃªncias do Chrome

### Debug

```bash
# Logs detalhados
DEBUG=* npm run dev

# Logs especÃ­ficos do scraper
docker-compose logs scraper-service

# Conectar no container
docker-compose exec backend sh
```

## ğŸ“ LicenÃ§a

MIT License - veja o arquivo LICENSE para detalhes.

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ Suporte

Para suporte e dÃºvidas:
- Email: alexvinitius@gmail.com
- GitHub Issues: Use as issues do repositÃ³rio

---

**ğŸ® Nexus Gaming Intelligence - Automatize seu marketing digital com IA!**